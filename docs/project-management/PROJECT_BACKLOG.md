# BYO RAG System - Task Backlog

## Overview
This document tracks the remaining user stories and features to be implemented for the RAG system.

**Total Remaining Story Points: 145** (89 GCP + 37 existing + 8 CI/CD + 11 observability)
- **GCP Deployment Epic**: 89 story points (CRITICAL - Top Priority)
- **Testing Stories**: 26 story points
- **Infrastructure Stories**: 19 story points (11 existing + 8 CI/CD)
- **Observability**: 11 story points

**üî• CURRENT PRIORITY: GCP Deployment - All GCP-related stories are P0 (Critical)**

---

## üöÄ GCP DEPLOYMENT EPIC (TOP PRIORITY)

### **GCP-INFRA-001: GCP Project Setup and Foundation** ‚úÖ **IMPLEMENTATION COMPLETE**
**Epic:** GCP Deployment
**Story Points:** 8
**Priority:** P0 - Critical (Prerequisite for all GCP deployment)
**Dependencies:** None

**Context:**
Establish GCP project foundation with required APIs, IAM configuration, and base infrastructure setup. This is the prerequisite for all subsequent GCP deployment tasks.

**Acceptance Criteria:**
- [x] GCP project created with billing enabled ‚úÖ
- [x] Required APIs enabled: GKE, Cloud SQL, Cloud Memorystore, Container Registry, Secret Manager, Cloud Build, IAM, Cloud Logging, Cloud Monitoring ‚úÖ
- [x] IAM service accounts created with least-privilege access ‚úÖ
- [x] VPC network configured with proper subnets and firewall rules ‚úÖ
- [x] Cloud NAT configured for private cluster egress ‚úÖ
- [x] Budget alerts configured to prevent cost overruns ‚úÖ

**Technical Tasks:**
- [x] Create GCP project via console or gcloud ‚úÖ
- [x] Enable billing account and set budget alerts ($1000/month initial) ‚úÖ
- [x] Enable required GCP APIs via script ‚úÖ
- [x] Create service accounts for: GKE nodes, Cloud SQL proxy, deployment automation ‚úÖ
- [x] Configure VPC with public/private subnets ‚úÖ
- [x] Set up Cloud Router and Cloud NAT ‚úÖ
- [x] Configure firewall rules for cluster communication ‚úÖ
- [x] Document project structure and naming conventions ‚úÖ

**Definition of Done:**
- [x] GCP project operational with all APIs enabled ‚úÖ
- [x] Service accounts created with documented permissions ‚úÖ
- [x] Network infrastructure ready for cluster deployment ‚úÖ
- [x] Budget monitoring active ‚úÖ
- [x] Infrastructure-as-code scripts for reproducibility ‚úÖ

**Business Impact:**
**CRITICAL** - Foundation for entire GCP deployment. Blocks all cloud infrastructure work.

**Implementation Summary:**
Created comprehensive automation scripts for GCP infrastructure setup:

**Scripts Created:**
- [scripts/gcp/00-setup-project.sh](../../scripts/gcp/00-setup-project.sh) - Project creation and API enablement
- [scripts/gcp/01-setup-network.sh](../../scripts/gcp/01-setup-network.sh) - VPC and networking
- [scripts/gcp/02-setup-service-accounts.sh](../../scripts/gcp/02-setup-service-accounts.sh) - IAM configuration
- [scripts/gcp/03-setup-budget-alerts.sh](../../scripts/gcp/03-setup-budget-alerts.sh) - Budget monitoring
- [scripts/gcp/README.md](../../scripts/gcp/README.md) - Usage documentation

**Features:**
- ‚úÖ Interactive project configuration with validation
- ‚úÖ Automated API enablement (15+ APIs)
- ‚úÖ Complete VPC networking with GKE-ready subnets
- ‚úÖ Firewall rules for internal, SSH, and health checks
- ‚úÖ Service accounts with Workload Identity support
- ‚úÖ Budget alerts (50%, 75%, 90%, 100% thresholds)
- ‚úÖ Comprehensive logging and summary reports
- ‚úÖ Environment-specific cost estimates

**Execution Time:** 45-55 minutes total

**Completion Date:** 2025-11-06

**Status:** READY FOR EXECUTION - Scripts are production-ready

---

### **GCP-SECRETS-002: Migrate Secrets to Google Secret Manager** ‚úÖ COMPLETE
**Epic:** GCP Deployment
**Story Points:** 5
**Priority:** P0 - Critical (Security vulnerability)
**Dependencies:** GCP-INFRA-001
**Status:** Complete - All secrets migrated and git history cleaned
**Implemented:** 2025-11-06
**Completed:** 2025-11-06

**Context:**
Current .env file contains hardcoded secrets including OpenAI API keys committed to version control. Must migrate to Google Secret Manager and rotate all credentials.

**Security Issues:**
- ‚úÖ OpenAI API key rotated and migrated to Secret Manager
- ‚úÖ JWT secret generated and stored in Secret Manager
- ‚úÖ Database passwords rotated and migrated
- ‚úÖ Redis password rotated and migrated
- ‚úÖ Git history cleaned of exposed secrets

**Acceptance Criteria:**
- [x] Migration automation script created
- [x] Secret rotation procedures documented
- [x] Git history removal script created
- [x] Local development helper script created
- [x] .gitignore updated with comprehensive patterns
- [x] IAM permission configuration automated
- [x] Execute migration script with new OpenAI key
- [x] Remove .env from git history
- [ ] Future: Update Kubernetes manifests (blocked by GCP-K8S-008)

**Technical Implementation:**

**Scripts Created:**
- [x] `scripts/gcp/04-migrate-secrets.sh` - Automated secret migration to Secret Manager
- [x] `scripts/gcp/05-remove-secrets-from-git.sh` - Remove secrets from git history
- [x] `scripts/gcp/06-create-local-env.sh` - Create local .env from Secret Manager
- [x] `.env.template` - Safe template file (generated by migration script)

**Documentation Created:**
- [x] `docs/security/SECRET_ROTATION_PROCEDURES.md` - Comprehensive rotation guide
  - PostgreSQL password rotation (90-day cycle)
  - Redis password rotation (90-day cycle)
  - JWT secret rotation (180-day cycle)
  - OpenAI API key rotation (as-needed)
  - Service account key rotation (90-day cycle)
  - Emergency compromise procedures
  - Compliance mapping (SOC 2, PCI DSS, HIPAA, ISO 27001)

**Features:**
- [x] Automatic secret generation (256-bit JWT, 192-bit passwords)
- [x] Secret Manager integration with metadata labels
- [x] IAM policy binding for GKE service accounts
- [x] Validation and rollback procedures
- [x] Comprehensive error handling
- [x] Dry-run validation
- [x] Git history cleanup with safety confirmations

**Execution Results:**

**Secrets Created in Google Secret Manager:**
- `postgres-password` - 192-bit rotated password
- `redis-password` - 192-bit rotated password  
- `jwt-secret` - 256-bit generated secret
- `openai-api-key` - Rotated service account key

**IAM Permissions Configured:**
- Service account: `gke-node-sa@byo-rag-dev.iam.gserviceaccount.com`
- Role: `roles/secretmanager.secretAccessor` on all secrets

**Git History:**
- `.env` removed from all commits
- Backup branch created: `backup-before-secret-removal-20251106-164351`
- Force pushed cleaned history to origin/main

**Files:**
- `.env.template` created as safe reference
- `.env.backup-20251106` preserved locally
- `.gitignore` updated to prevent future commits

**Definition of Done:**
- [x] Migration scripts created and validated ‚úÖ
- [x] Rotation procedures documented ‚úÖ
- [x] Git history removal script ready ‚úÖ
- [x] .gitignore updated ‚úÖ
- [x] Secrets migrated to Secret Manager ‚úÖ
- [x] .env removed from git history ‚úÖ
- [ ] Services authenticate with new credentials (pending GCP-K8S-008)

**Next Steps:**
1. ‚úÖ COMPLETE - All secrets migrated and secured
2. GCP-K8S-008 will integrate Secret Manager CSI driver for Kubernetes
3. Update service configurations to use Secret Manager (part of GCP-K8S-008)
4. Verify all services authenticate correctly in GCP deployment

**Business Impact:**
**COMPLETE** - Security vulnerability resolved. All secrets rotated and git history cleaned.

---

### **GCP-REGISTRY-003: Container Registry Setup and Image Publishing** ‚úÖ COMPLETE
**Epic:** GCP Deployment
**Story Points:** 8
**Priority:** P0 - Critical (Blocks deployment)
**Dependencies:** GCP-INFRA-001, GCP-SECRETS-002
**Status:** Complete - All images published to Artifact Registry
**Completed:** 2025-11-07

**Context:**
Docker images currently built locally. Need to publish to Google Artifact Registry with proper tagging, versioning, and automated builds.

**Acceptance Criteria:**
- [x] Artifact Registry repository created (rag-system)
- [x] All 5 service images built and pushed to registry
- [x] Image tagging strategy implemented (semver + git SHA)
- [x] Automated build pipeline configured
- [x] Vulnerability scanning enabled on all images
- [ ] Image pull secrets configured for GKE (blocked by GCP-K8S-008)

**Services Published:**
- ‚úÖ rag-auth-service
- ‚úÖ rag-document-service
- ‚úÖ rag-embedding-service
- ‚úÖ rag-core-service
- ‚úÖ rag-admin-service

**Technical Tasks:**
- [x] Create Artifact Registry repository
- [x] Configure Docker authentication to Artifact Registry
- [x] Build all 5 service images locally
- [x] Tag images with version and git SHA (4 tags per image)
- [x] Push images to Artifact Registry
- [x] Enable vulnerability scanning (Container Analysis API)
- [x] Document image build and push procedures
- [ ] Create image pull secret for GKE (part of GCP-K8S-008)

**Implementation Details:**

**Registry Location:**
```
us-central1-docker.pkg.dev/byo-rag-dev/rag-system
```

**Image Tagging Strategy:**
Each service image has 4 tags:
- `0.8.0` - Version from pom.xml
- `9e46cdd` - Git commit SHA
- `latest` - Always points to most recent build
- `0.8.0-9e46cdd` - Combined version+SHA for traceability

**Scripts Created:**
- [x] `scripts/gcp/07-build-and-push-images.sh` - Automated build and push
  - Builds all 5 services or specific service
  - Multi-stage tagging strategy
  - Dry-run mode for testing
  - Comprehensive error handling
  - Skip-build option for re-tagging

**Files Modified:**
- [x] `.dockerignore` - Fixed to include JAR files in build context

**Vulnerability Scanning:**
- Container Analysis API enabled
- Automatic scanning on push
- Scans for OS, Maven, NPM, PyPI, Ruby, Go, Rust packages
- CVSS scoring and severity classification
- Continuous analysis for new vulnerabilities

**Definition of Done:**
- [x] All service images in Artifact Registry
- [x] Images scanned for vulnerabilities (scanning active)
- [ ] GKE can pull images successfully (requires GCP-K8S-008)
- [x] Automated build scripts created
- [x] Versioning strategy documented

**Usage Examples:**

**Pull an image:**
```bash
docker pull us-central1-docker.pkg.dev/byo-rag-dev/rag-system/rag-core-service:0.8.0
```

**Use in Kubernetes:**
```yaml
image: us-central1-docker.pkg.dev/byo-rag-dev/rag-system/rag-core-service:0.8.0
```

**Rebuild and push all images:**
```bash
./scripts/gcp/07-build-and-push-images.sh
```

**Build specific service:**
```bash
./scripts/gcp/07-build-and-push-images.sh --service rag-core-service
```

**View in Console:**
https://console.cloud.google.com/artifacts/docker/byo-rag-dev/us-central1/rag-system

**Business Impact:**
**COMPLETE** - All container images are now available in GCP for deployment. Unblocks GCP-K8S-008.

---

### **GCP-SQL-004: Cloud SQL PostgreSQL Migration** ‚úÖ COMPLETE
**Epic:** GCP Deployment
**Story Points:** 13
**Priority:** P0 - Critical (Core infrastructure)
**Dependencies:** GCP-INFRA-001, GCP-SECRETS-002
**Status:** Complete - Cloud SQL operational with pgvector enabled
**Implemented:** 2025-11-07
**Completed:** 2025-11-07

**Context:**
Migrate from containerized PostgreSQL to Cloud SQL for production-grade reliability, automated backups, and high availability.

**Acceptance Criteria:**
- [x] Cloud SQL instance provisioned with pgvector extension ‚úÖ
- [x] Database schemas created (rag_auth, rag_document, rag_admin) ‚úÖ
- [x] Cloud SQL Proxy instructions documented ‚úÖ
- [x] Automated backups configured (daily, 7-day retention) ‚úÖ
- [ ] High availability enabled (production) - ‚è≥ Zonal for cost savings
- [x] Connection pooling documented ‚úÖ
- [ ] All services connected to Cloud SQL - ‚è≥ Pending GCP-K8S-008

**Implementation Summary:**
Created comprehensive Cloud SQL PostgreSQL 15 instance with pgvector support.

**Instance Details:**
- **Instance Name**: `rag-postgres`
- **Public IP**: `104.197.76.156`
- **Connection**: `byo-rag-dev:us-central1:rag-postgres`
- **Tier**: db-custom-2-7680 (2 vCPU, 7.5 GB RAM)
- **Storage**: 20 GB SSD with auto-increase
- **Availability**: Zonal (us-central1-a)

**Databases:**
- `rag_auth` - Authentication service
- `rag_document` - Document service  
- `rag_admin` - Admin service
- All databases have pgvector 0.8.0 extension enabled

**Security:**
- IAM authentication enabled
- All credentials in Secret Manager
- SSL enforced for connections
- Public IP with authorized networks (temporary, private IP pending)

**Scripts Created:**
- [scripts/gcp/08-setup-cloud-sql.sh](../../scripts/gcp/08-setup-cloud-sql.sh) - Instance and database setup
- [scripts/gcp/09-enable-pgvector.sh](../../scripts/gcp/09-enable-pgvector.sh) - pgvector extension enablement

**Documentation:**
- [docs/deployment/CLOUD_SQL_SETUP.md](../deployment/CLOUD_SQL_SETUP.md) - Complete setup guide

**Cost Estimate:** ~$77-85/month

**Definition of Done:**
- [x] Cloud SQL instance operational ‚úÖ
- [ ] All services successfully connected - ‚è≥ Pending GCP-K8S-008
- [x] Automated backups verified ‚úÖ
- [x] Disaster recovery procedures documented ‚úÖ
- [ ] Database performance benchmarks - ‚è≥ Pending service migration

**Business Impact:**
**CRITICAL** - Core data persistence layer for entire system.

**Completion Date:** 2025-11-07

---

### **GCP-REDIS-005: Cloud Memorystore Redis Migration** ‚úÖ COMPLETE
**Epic:** GCP Deployment
**Story Points:** 8
**Priority:** P0 - Critical (Core infrastructure)
**Dependencies:** GCP-INFRA-001, GCP-SECRETS-002
**Status:** Complete - Cloud Memorystore operational with high availability
**Implemented:** 2025-11-09
**Completed:** 2025-11-09

**Context:**
Migrate from containerized Redis Stack to Cloud Memorystore for managed caching and vector operations.

**Acceptance Criteria:**
- [x] Cloud Memorystore instance provisioned ‚úÖ
- [x] Redis version compatible with current code (7.0+) ‚úÖ
- [x] High availability configured (Standard HA tier) ‚úÖ
- [ ] All services connected to Memorystore - ‚è≥ Pending GCP-K8S-008
- [ ] Vector operations tested and verified - ‚è≥ Pending service migration
- [x] Monitoring and alerting guidelines documented ‚úÖ

**Implementation Summary:**
Created fully managed Cloud Memorystore Redis 7.0 instance with high availability.

**Instance Details:**
- **Instance Name**: `rag-redis`
- **Private IP**: `10.170.252.12`
- **Port**: `6379`
- **Region**: `us-central1`
- **Zone**: `us-central1-a`
- **Tier**: `STANDARD_HA` (High Availability)
- **Memory**: 5 GB
- **Redis Version**: 7.0

**High Availability:**
- Master-replica replication across zones
- Automatic failover (<30 seconds)
- Zero data loss with synchronous replication
- Monthly maintenance with minimal downtime

**Security:**
- Redis AUTH enabled
- Private IP only (VPC peering)
- Password in Secret Manager: `memorystore-redis-password`
- Connection info in Secret Manager: `memorystore-connection-info`
- IAM access granted to GKE service account

**Database Allocation:**
- Database 0: Auth service (JWT tokens, sessions)
- Database 1: Core service (query cache, rate limiting)
- Database 2: Embedding service (vector cache)

**Scripts Created:**
- [scripts/gcp/10-setup-memorystore.sh](../../scripts/gcp/10-setup-memorystore.sh) - Instance creation and AUTH setup

**Documentation:**
- [docs/deployment/CLOUD_MEMORYSTORE_SETUP.md](../deployment/CLOUD_MEMORYSTORE_SETUP.md) - Complete setup guide

**Cost Estimate:** ~$230-250/month

**Performance:**
- Latency: <2ms (same region)
- Throughput: ~80,000 ops/sec
- Concurrent connections: Thousands

**Definition of Done:**
- [x] Memorystore instance operational ‚úÖ
- [ ] All services connected successfully - ‚è≥ Pending GCP-K8S-008
- [ ] Vector similarity search working - ‚è≥ Pending testing
- [x] High availability configured ‚úÖ
- [x] Performance benchmarks documented ‚úÖ

**Business Impact:**
**CRITICAL** - Required for vector embeddings and caching layer.

**Completion Date:** 2025-11-09

---

### **GCP-KAFKA-006: Kafka/Pub-Sub Migration Strategy**
**Epic:** GCP Deployment
**Story Points:** 13
**Priority:** P0 - Critical (Event-driven architecture)
**Dependencies:** GCP-INFRA-001

**Context:**
Evaluate and migrate from containerized Kafka to either Cloud Pub/Sub or managed Kafka (Confluent Cloud). Cloud Pub/Sub is simpler but requires code changes; Confluent Cloud is drop-in replacement.

**Decision Required:**
- **Option A**: Cloud Pub/Sub (GCP native, lower cost, simpler operations)
- **Option B**: Confluent Cloud on GCP (Kafka-compatible, no code changes)

**Acceptance Criteria:**
- [ ] Kafka migration strategy decided and documented
- [ ] Managed service provisioned and configured
- [ ] Topics migrated with proper naming
- [ ] All services publishing/consuming messages successfully
- [ ] Message ordering and delivery guarantees maintained
- [ ] Dead letter queues configured
- [ ] Monitoring and alerting set up

**Technical Tasks (Cloud Pub/Sub):**
- [ ] Create Pub/Sub topics for: document-processing, embedding-requests, rag-queries
- [ ] Implement Pub/Sub client libraries in services
- [ ] Migrate Kafka consumers to Pub/Sub subscribers
- [ ] Migrate Kafka producers to Pub/Sub publishers
- [ ] Configure message retention and acknowledgement
- [ ] Test end-to-end message flows
- [ ] Set up monitoring dashboards

**Technical Tasks (Confluent Cloud):**
- [ ] Provision Confluent Cloud cluster
- [ ] Migrate Kafka topics
- [ ] Update connection strings to Confluent Cloud
- [ ] Configure authentication (API keys)
- [ ] Test all producers and consumers
- [ ] Set up monitoring integration

**Definition of Done:**
- [ ] Messaging infrastructure operational
- [ ] All async workflows functioning
- [ ] Message delivery reliability tested
- [ ] No message loss during migration
- [ ] Cost analysis completed

**Business Impact:**
**CRITICAL** - Core event-driven architecture for async document processing.

---

### **GCP-GKE-007: GKE Cluster Provisioning**
**Epic:** GCP Deployment
**Story Points:** 13
**Priority:** P0 - Critical (Core infrastructure)
**Dependencies:** GCP-INFRA-001

**Context:**
Provision production-ready GKE cluster with autoscaling, monitoring, and security best practices.

**Acceptance Criteria:**
- [ ] GKE cluster created with appropriate node pools
- [ ] Cluster autoscaling configured
- [ ] Workload Identity enabled
- [ ] Network policies configured
- [ ] GKE monitoring and logging enabled
- [ ] kubectl access configured for deployment

**Technical Tasks:**
- [ ] Create GKE cluster (zonal for dev, regional for prod)
- [ ] Configure node pools: system (e2-standard-2), workload (n1-standard-4)
- [ ] Enable cluster autoscaling (min 3, max 10 nodes)
- [ ] Enable Workload Identity for pod-level IAM
- [ ] Configure network policies for pod security
- [ ] Enable GKE monitoring and logging
- [ ] Configure cluster access and RBAC
- [ ] Install cluster add-ons: ingress controller, cert-manager
- [ ] Test cluster connectivity and authentication

**Definition of Done:**
- [ ] GKE cluster operational and accessible
- [ ] Autoscaling tested and verified
- [ ] Security controls in place
- [ ] Monitoring dashboards created
- [ ] kubectl access working for deployment team

**Business Impact:**
**CRITICAL** - Foundation for running all microservices.

---

### **GCP-K8S-008: Kubernetes Manifests for GCP**
**Epic:** GCP Deployment
**Story Points:** 13
**Priority:** P0 - Critical (Deployment configuration)
**Dependencies:** GCP-GKE-007, GCP-SQL-004, GCP-REDIS-005, GCP-REGISTRY-003

**Context:**
Update existing Kubernetes manifests for GCP-specific configurations including Cloud SQL proxy, Secret Manager CSI, and Artifact Registry images.

**Acceptance Criteria:**
- [ ] All deployments updated with GCP image references
- [ ] Cloud SQL Proxy sidecar configured
- [ ] Secret Manager CSI driver integrated
- [ ] Resource requests/limits tuned for GKE
- [ ] Health checks and probes configured
- [ ] ConfigMaps created for environment-specific config
- [ ] Service manifests with GCP load balancer annotations

**Technical Tasks:**
- [ ] Update all image references to gcr.io/PROJECT-ID/
- [ ] Add Cloud SQL Proxy sidecar to auth, document, admin services
- [ ] Configure Secret Manager CSI driver for secrets
- [ ] Create environment-specific overlays (dev/staging/prod)
- [ ] Configure resource requests and limits per service
- [ ] Update health check endpoints and timing
- [ ] Configure horizontal pod autoscalers (HPA)
- [ ] Create service accounts with Workload Identity bindings
- [ ] Test manifests in dev cluster

**Services to Configure:**
- rag-auth (8081) - needs Cloud SQL
- rag-document (8082) - needs Cloud SQL, persistent volumes
- rag-embedding (8083) - needs Redis
- rag-core (8084) - needs Redis
- rag-admin (8085) - needs Cloud SQL

**Definition of Done:**
- [ ] All manifests validated and working in dev cluster
- [ ] Services can connect to Cloud SQL and Memorystore
- [ ] Secrets loaded from Secret Manager
- [ ] Health checks passing
- [ ] Autoscaling tested

**Business Impact:**
**CRITICAL** - Required for deploying services to GKE.

---

### **GCP-STORAGE-009: Persistent Storage Configuration**
**Epic:** GCP Deployment
**Story Points:** 5
**Priority:** P0 - Critical (Document storage)
**Dependencies:** GCP-GKE-007

**Context:**
Configure GCP persistent disks for document storage. Currently using Docker volumes.

**Acceptance Criteria:**
- [ ] StorageClass configured for SSD persistent disks
- [ ] PersistentVolumeClaims created for document service
- [ ] Backup strategy implemented
- [ ] Multi-zone replication enabled (production)
- [ ] Volume snapshots configured

**Technical Tasks:**
- [ ] Create StorageClass for pd-ssd
- [ ] Create PVC for document-storage (100GB initial)
- [ ] Update document service deployment with volume mounts
- [ ] Configure automated volume snapshots
- [ ] Test volume persistence and failover
- [ ] Document volume expansion procedures

**Definition of Done:**
- [ ] Document storage persists across pod restarts
- [ ] Snapshots created successfully
- [ ] Volume expansion tested
- [ ] Backup/restore procedures documented

**Business Impact:**
**CRITICAL** - Required for document persistence.

---

### **GCP-INGRESS-010: Ingress and Load Balancer Configuration**
**Epic:** GCP Deployment
**Story Points:** 8
**Priority:** P0 - Critical (External access)
**Dependencies:** GCP-K8S-008, GCP-GKE-007

**Context:**
Configure GCP load balancer, ingress controller, SSL certificates, and Cloud Armor for production traffic.

**Acceptance Criteria:**
- [ ] GKE Ingress configured with GCP load balancer
- [ ] SSL/TLS certificates provisioned (Google-managed)
- [ ] Cloud Armor WAF rules configured
- [ ] DNS configured (Cloud DNS)
- [ ] Health checks configured on load balancer
- [ ] Rate limiting enabled

**Technical Tasks:**
- [ ] Reserve static external IP address
- [ ] Configure Ingress resource with GCP annotations
- [ ] Set up Google-managed SSL certificates
- [ ] Configure Cloud Armor security policy
- [ ] Set up Cloud DNS zone and records
- [ ] Configure backend services and health checks
- [ ] Implement rate limiting rules
- [ ] Test external access and SSL

**Definition of Done:**
- [ ] Services accessible via HTTPS
- [ ] SSL certificates valid and auto-renewing
- [ ] Cloud Armor protecting against common attacks
- [ ] DNS resolving correctly
- [ ] Health checks passing

**Business Impact:**
**CRITICAL** - Required for external access to system.

---

### **GCP-DEPLOY-011: Initial Service Deployment**
**Epic:** GCP Deployment
**Story Points:** 8
**Priority:** P0 - Critical (First deployment)
**Dependencies:** GCP-K8S-008, GCP-INGRESS-010

**Context:**
Deploy all 5 microservices to GKE for the first time and validate end-to-end functionality.

**Acceptance Criteria:**
- [ ] All 5 services deployed to GKE
- [ ] All pods running and healthy
- [ ] Services can communicate with each other
- [ ] Integration tests passing in GKE environment
- [ ] Swagger UI accessible and functional
- [ ] Admin user created and authenticated

**Technical Tasks:**
- [ ] Deploy services in dependency order
- [ ] Verify pod startup and health checks
- [ ] Run database migrations
- [ ] Create admin user in Cloud SQL
- [ ] Test service-to-service communication
- [ ] Run integration test suite
- [ ] Validate Swagger UI access
- [ ] Test full RAG workflow

**Deployment Order:**
1. rag-auth-service
2. rag-admin-service
3. rag-document-service
4. rag-embedding-service
5. rag-core-service

**Definition of Done:**
- [ ] All services deployed and healthy
- [ ] Integration tests passing
- [ ] Full RAG workflow functional
- [ ] Monitoring data flowing
- [ ] Logs centralized in Cloud Logging

**Business Impact:**
**CRITICAL** - First working deployment in GCP.

---

## Active Backlog Stories

### **AUTH-FIX-001: Fix Admin Service BCrypt Authentication Validation** ‚úÖ **COMPLETED**
**Epic:** Authentication & Authorization Infrastructure  
**Story Points:** 8  
**Priority:** P0 - Critical (Blocking administrative operations)  
**Dependencies:** None

**Context:**
Admin service authentication endpoint consistently returns "Invalid credentials" for `admin@enterprise-rag.com` despite valid user, correct BCrypt hashes, and proper request format. This blocked all administrative functionality including tenant management, user administration, and system analytics.

**Resolution Summary:**
- ‚úÖ **Root Cause Identified**: Database contained incorrect BCrypt hash for admin user
- ‚úÖ **Solution Implemented**: Updated password_hash with verified working BCrypt hash `$2a$10$4ruqE8FlnERNCuIW/6pI6.1rlZmJiG/plwFwif5KPGxjwbM9Sm6je`
- ‚úÖ **Scripts Updated**: Fixed admin email in test scripts from `admin@enterprise.com` to `admin@enterprise-rag.com`
- ‚úÖ **Validation Complete**: All integration tests passing, admin authentication fully functional

**Acceptance Criteria:**
- [x] Admin user `admin@enterprise-rag.com` authenticates with password `admin123`
- [x] Authentication returns valid JWT token with ADMIN role claims
- [x] JWT token works for accessing protected admin endpoints
- [x] Authentication logging shows successful login without warnings
- [x] BCrypt validation matches standard Spring Security implementation

**Definition of Done:**
- [x] Admin authentication works for existing credentials
- [x] All admin endpoints accessible with generated JWT tokens
- [x] Unit and integration tests pass
- [x] Authentication performance <500ms
- [x] Security audit confirms no vulnerabilities introduced

**Business Impact:**
**RESOLVED** - Admin operations, tenant management, and system oversight fully operational.

**Completion Date:** 2025-09-29

---

### **DOCKER-HEALTH-011: Fix Admin Service Docker Health Check Configuration**
**Epic:** Deployment & Infrastructure  
**Story Points:** 3  
**Priority:** Low (Cosmetic Issue)  
**Dependencies:** None

**Context:**
The `rag-admin` container shows as "unhealthy" in Docker status despite the service being fully functional. The Docker health check is configured to check `/actuator/health`, but the admin service actually serves its health endpoint at `/admin/api/actuator/health` due to the service's context path configuration.

**Problem Evidence:**
- ‚ùå Docker health check: `http://localhost:8085/actuator/health` ‚Üí Returns 404 Not Found
- ‚úÖ Actual health endpoint: `http://localhost:8085/admin/api/actuator/health` ‚Üí Returns 200 OK
- ‚úÖ Service functionality: 100% operational, all integration tests pass
- ‚ùå Container status: Shows as "unhealthy" in `docker ps` and docker-compose health checks

**Current Impact:**
- **Functional Impact**: NONE - Service works perfectly
- **Visual Impact**: Container appears unhealthy in Docker tooling
- **Monitoring Impact**: May trigger false alerts in production monitoring

**Root Cause:**
Dockerfile health check configuration uses wrong endpoint path:
```dockerfile
# Current (incorrect)
HEALTHCHECK CMD wget --spider http://localhost:8085/actuator/health

# Should be
HEALTHCHECK CMD wget --spider http://localhost:8085/admin/api/actuator/health
```

**Acceptance Criteria:**
- [ ] Docker health check uses correct endpoint `/admin/api/actuator/health`
- [ ] `rag-admin` container shows as "healthy" in `docker ps`
- [ ] Health check passes without affecting service functionality
- [ ] Docker compose health status shows GREEN for admin service
- [ ] No regression in actual service operation

**Technical Tasks:**
- [ ] Update Dockerfile health check endpoint path
- [ ] Rebuild admin service Docker image with corrected health check
- [ ] Test health check with manual verification
- [ ] Update docker-compose configuration if needed
- [ ] Verify no Docker build cache issues interfere with deployment

**Definition of Done:**
- [ ] Admin service container shows as "healthy" in Docker status
- [ ] Health check endpoint returns successful HTTP 200 response
- [ ] Service functionality remains 100% operational
- [ ] Documentation updated with correct health check configuration
- [ ] No false negative health alerts in monitoring

**Business Impact:**
**LOW** - Cosmetic issue that doesn't affect functionality but improves operational visibility and prevents false monitoring alerts.

**Current Status:**
Service is fully functional despite health check display issue. This is a maintenance/polish task for improved operational experience.

---



### **GATEWAY-TEST-005: Gateway Security and Routing Tests** ‚úÖ **COMPLETED**
**Epic:** Testing Foundation  
**Story Points:** 8  
**Priority:** Critical (Security Gap)  
**Dependencies:** None

**Context:**
Implement comprehensive security and routing tests for API gateway to prevent security vulnerabilities.

**Acceptance Criteria:**
- [x] Security tests for API authentication and authorization
- [x] Tests for request routing and load balancing
- [x] Input validation and sanitization tests
- [x] Rate limiting and throttling tests
- [x] CORS and security headers validation
- [x] Tests for malicious request handling

**Definition of Done:**
- [x] Complete security test coverage for gateway
- [x] Performance tests for routing efficiency
- [x] Security vulnerability scanning
- [x] Load testing for high traffic scenarios
- [x] Documentation of security test scenarios

**Business Impact:**
Critical for preventing security vulnerabilities in API gateway layer.

**Implementation Summary:**
- **GatewaySecurityComprehensiveTest.java**: 22/22 tests passing, covering all acceptance criteria
- **Comprehensive Test Coverage**: Authentication, authorization, routing, input validation, rate limiting, CORS, malicious request handling
- **Security Features Validated**: JWT validation, XSS prevention, SQL injection protection, path traversal prevention, security headers

---


### **INTEGRATION-TEST-008: End-to-End Workflow Tests** ‚≠ê **HIGH IMPACT**
**Epic:** Testing Foundation  
**Story Points:** 13  
**Priority:** High (Impact)  
**Dependencies:** None

**Context:**
Implement comprehensive end-to-end testing for complete user workflows across all services.

**Acceptance Criteria:**
- [ ] Full document upload to embedding workflow tests
- [ ] User authentication to document access workflow tests
- [ ] Search and retrieval workflow tests
- [ ] Admin management workflow tests
- [ ] Error recovery and fallback workflow tests
- [ ] Multi-user concurrent workflow tests

**Definition of Done:**
- [ ] Complete end-to-end test automation
- [ ] Performance benchmarks for full workflows
- [ ] User acceptance testing scenarios
- [ ] Cross-service integration validation
- [ ] Monitoring and alerting integration

**Business Impact:**
Validates complete system functionality and user experience.

---

### **PERFORMANCE-TEST-009: Performance and Load Testing**
**Epic:** Testing Foundation  
**Story Points:** 8  
**Priority:** High  
**Dependencies:** None

**Context:**
Implement comprehensive performance and load testing across all system components.

**Acceptance Criteria:**
- [ ] Load testing for concurrent user scenarios
- [ ] Stress testing for system breaking points
- [ ] Performance benchmarking for key operations
- [ ] Memory and resource usage profiling
- [ ] Database performance under load
- [ ] Network latency and throughput testing

**Definition of Done:**
- [ ] Performance benchmarks established
- [ ] Load testing automation in CI/CD
- [ ] Performance regression detection
- [ ] Scalability recommendations documented
- [ ] Resource optimization implemented

**Business Impact:**
Ensures system performance meets production requirements.

---

### **CONTRACT-TEST-010: Service Contract Testing**
**Epic:** Testing Foundation  
**Story Points:** 5  
**Priority:** Medium  
**Dependencies:** None

**Context:**
Implement contract testing between services to ensure API compatibility and prevent breaking changes.

**Acceptance Criteria:**
- [ ] API contract definition and validation
- [ ] Contract tests between all service pairs
- [ ] Backward compatibility testing
- [ ] Version compatibility testing
- [ ] Contract violation detection and alerting

**Definition of Done:**
- [ ] Complete contract test coverage
- [ ] Contract testing in CI/CD pipeline
- [ ] API versioning strategy implemented
- [ ] Breaking change detection system
- [ ] Service dependency documentation

**Business Impact:**
Prevents service integration issues and breaking changes.

---

### **GATEWAY-CSRF-012: Fix Gateway CSRF Authentication Blocking**
**Epic:** Deployment & Infrastructure  
**Story Points:** 8  
**Priority:** Medium (Operational Enhancement)  
**Dependencies:** None

**Context:**
The API Gateway has persistent CSRF protection that prevents authentication requests to `/api/auth/login` despite multiple attempts to disable CSRF in the security configuration. This blocks Swagger UI authentication and requires users to access services directly instead of through the unified gateway.

**Problem Evidence:**
- ‚ùå Gateway auth endpoint: `POST /api/auth/login` ‚Üí Returns "An expected CSRF token cannot be found" (HTTP 403)
- ‚úÖ Direct auth service: `POST localhost:8081/api/v1/auth/login` ‚Üí Returns valid JWT tokens (HTTP 200)
- ‚ùå Spring Security auto-configuration overriding custom security configuration
- ‚ùå Multiple security filter chains causing configuration conflicts

**Root Cause Analysis:**
Spring Boot's reactive security auto-configuration is creating default security filter chains that take precedence over custom `SecurityWebFilterChain` configuration, despite:
- Custom `@Order(HIGHEST_PRECEDENCE)` security configuration
- Explicit CSRF disable: `.csrf(ServerHttpSecurity.CsrfSpec::disable)`
- Auto-configuration exclusions for `ReactiveSecurityAutoConfiguration`
- Application properties: `spring.security.csrf.enabled: false`

**Current Impact:**
- **Functional**: Minimal - All services work via direct access
- **User Experience**: Users must use individual service Swagger UIs instead of unified gateway
- **Development**: Requires knowledge of individual service ports and endpoints
- **Monitoring**: Bypasses centralized gateway metrics and logging

**Acceptance Criteria:**
- [ ] Gateway accepts POST requests to `/api/auth/login` without CSRF token
- [ ] Gateway Swagger UI authentication works with admin credentials
- [ ] Gateway auth endpoint returns valid JWT tokens (matching direct auth service)
- [ ] No regression in security for protected endpoints
- [ ] Gateway properly forwards authentication requests to Auth Service

**Technical Investigation Required:**
- [ ] Complete Spring Security filter chain analysis and mapping
- [ ] Identify conflicting security configurations in Spring Cloud Gateway
- [ ] Research Gateway-specific security configuration patterns
- [ ] Evaluate custom authentication filter implementation approach
- [ ] Consider WebFlux security configuration alternatives

**Technical Approaches to Explore:**
1. **Complete Security Auto-Configuration Bypass**: Remove all Spring Security and implement custom filters
2. **Gateway-Specific Security Configuration**: Use Spring Cloud Gateway security patterns
3. **Custom Authentication Filter**: Implement gateway-level authentication without Spring Security
4. **Profile-Based Configuration**: Isolate security configuration by deployment profile
5. **WebFlux Security Pattern Review**: Ensure reactive security best practices

**Definition of Done:**
- [ ] Gateway authentication endpoint accessible via curl and Swagger UI
- [ ] Authentication flow: Gateway ‚Üí Auth Service ‚Üí JWT token return
- [ ] No CSRF errors for authentication endpoints
- [ ] Security maintained for all other protected endpoints  
- [ ] Integration tests pass with Gateway authentication
- [ ] Documentation updated with Gateway authentication examples

**Business Impact:**
**MEDIUM** - Improves developer experience and operational consistency by enabling unified gateway access. Not critical for functionality but important for production operational experience.

**Alternative Workarounds Available:**
- Direct service access: `http://localhost:8081/api/v1/auth/login` (fully functional)
- Individual service Swagger UIs work correctly
- API testing tools (Postman, curl) work with direct endpoints

---

---

## üîÑ CI/CD & OBSERVABILITY

### **GCP-CICD-012: Cloud Build CI/CD Pipeline**
**Epic:** GCP Deployment
**Story Points:** 8
**Priority:** P1 - High (Automation)
**Dependencies:** GCP-REGISTRY-003, GCP-DEPLOY-011

**Context:**
Implement automated CI/CD pipeline using Cloud Build for continuous integration, testing, and deployment.

**Acceptance Criteria:**
- [ ] Cloud Build triggers configured for git commits
- [ ] Automated builds on pull requests
- [ ] Unit and integration tests run in pipeline
- [ ] Automated deployment to dev environment
- [ ] Manual approval for staging/production
- [ ] Build status notifications

**Technical Tasks:**
- [ ] Create cloudbuild.yaml for each service
- [ ] Configure Cloud Build triggers (on commit, PR)
- [ ] Implement multi-stage builds (test, build, push)
- [ ] Set up automated deployment to dev cluster
- [ ] Configure Slack/email notifications
- [ ] Implement rollback procedures
- [ ] Document CI/CD workflow

**Definition of Done:**
- [ ] Automated builds working for all services
- [ ] Tests run on every commit
- [ ] Successful builds auto-deploy to dev
- [ ] Build failures notify team
- [ ] Deployment history tracked

**Business Impact:**
**HIGH** - Enables rapid iteration and reduces manual deployment effort.

---

### **GCP-OBSERVABILITY-013: Cloud Monitoring and Logging**
**Epic:** GCP Deployment
**Story Points:** 8
**Priority:** P1 - High (Production readiness)
**Dependencies:** GCP-DEPLOY-011

**Context:**
Configure comprehensive monitoring, logging, and alerting using GCP native services.

**Acceptance Criteria:**
- [ ] Cloud Logging configured for all services
- [ ] Cloud Monitoring dashboards created
- [ ] Alerting policies configured
- [ ] Error Reporting integrated
- [ ] Cloud Trace for distributed tracing
- [ ] Custom metrics exported

**Technical Tasks:**
- [ ] Configure log aggregation from GKE
- [ ] Create monitoring dashboards for key metrics
- [ ] Set up alerting policies (CPU, memory, errors)
- [ ] Integrate Error Reporting
- [ ] Configure Cloud Trace for request tracing
- [ ] Export custom application metrics
- [ ] Create runbooks for common alerts

**Definition of Done:**
- [ ] All logs centralized in Cloud Logging
- [ ] Dashboards showing system health
- [ ] Alerts configured and tested
- [ ] Distributed tracing working
- [ ] On-call runbooks documented

**Business Impact:**
**HIGH** - Critical for production operations and incident response.

---

### **GCP-COST-014: Cost Optimization and Monitoring**
**Epic:** GCP Deployment
**Story Points:** 3
**Priority:** P2 - Medium (Cost control)
**Dependencies:** GCP-DEPLOY-011

**Context:**
Implement cost monitoring, optimization strategies, and budget controls to manage GCP spending.

**Acceptance Criteria:**
- [ ] Budget alerts configured
- [ ] Cost allocation labels applied
- [ ] Resource utilization analyzed
- [ ] Optimization recommendations implemented
- [ ] Cost dashboard created

**Technical Tasks:**
- [ ] Set up budget alerts at $500, $750, $1000
- [ ] Apply labels to all resources (env, service, team)
- [ ] Enable committed use discounts for predictable workloads
- [ ] Configure autoscaling to minimize idle resources
- [ ] Review and right-size instance types
- [ ] Create cost monitoring dashboard

**Definition of Done:**
- [ ] Budget alerts active
- [ ] All resources labeled
- [ ] Cost optimization plan documented
- [ ] Monthly cost reports automated

**Business Impact:**
**MEDIUM** - Prevents cost overruns and optimizes cloud spending.

---

## Summary

### Remaining Backlog

#### üî• **Critical Priority (GCP Deployment) - 68 Story Points**
**Must complete for GCP deployment:**
1. GCP-INFRA-001: Project Setup (8 pts) - ‚úÖ COMPLETE
2. GCP-SECRETS-002: Secret Manager Migration (5 pts) - ‚úÖ COMPLETE
3. GCP-REGISTRY-003: Container Registry (8 pts) - ‚úÖ COMPLETE
4. GCP-SQL-004: Cloud SQL Migration (13 pts) - ‚úÖ COMPLETE
5. GCP-REDIS-005: Cloud Memorystore (8 pts) - ‚úÖ COMPLETE
6. GCP-KAFKA-006: Kafka/Pub-Sub (13 pts) - **NEXT PRIORITY**
7. GCP-GKE-007: GKE Cluster (13 pts)
8. GCP-K8S-008: Kubernetes Manifests (13 pts)
9. GCP-STORAGE-009: Persistent Storage (5 pts)
10. GCP-INGRESS-010: Ingress & Load Balancer (8 pts)
11. GCP-DEPLOY-011: Initial Deployment (8 pts)

**Progress: 42 of 89 story points complete (47%)**

**Estimated Timeline: 2-3 weeks remaining**

#### High Priority - 37 Story Points
- GCP-CICD-012: CI/CD Pipeline (8 pts)
- GCP-OBSERVABILITY-013: Monitoring & Logging (8 pts)
- INTEGRATION-TEST-008: E2E Tests (13 pts)
- PERFORMANCE-TEST-009: Load Testing (8 pts)

#### Medium Priority - 16 Story Points
- GCP-COST-014: Cost Optimization (3 pts)
- CONTRACT-TEST-010: Service Contracts (5 pts)
- GATEWAY-CSRF-012: Gateway CSRF Fix (8 pts)

#### Low Priority - 3 Story Points
- DOCKER-HEALTH-011: Admin Health Check (3 pts)

### Overall Metrics
- **Total Remaining Story Points**: 145
- **Critical (GCP Deployment)**: 89 points (61%)
- **High Priority**: 37 points (26%)
- **Medium Priority**: 16 points (11%)
- **Low Priority**: 3 points (2%)

### Next Actions
1. **IMMEDIATE**: Start GCP-INFRA-001 (Project Setup)
2. **SECURITY**: Complete GCP-SECRETS-002 (rotate exposed API keys)
3. **FOLLOW DEPENDENCY CHAIN**: Complete GCP stories in order
4. **TARGET**: First GCP deployment in 3-4 weeks